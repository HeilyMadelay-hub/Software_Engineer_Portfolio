üéØ Sistema de Reconocimiento de Gestos Est√°ticos (POSE)

Sistema de entrenamiento y detecci√≥n online de gestos est√°ticos en Lengua de Signos Espa√±ola (LSE) basado en an√°lisis de poses de mano capturadas con MediaPipe. Genera firmas normalizadas invariantes a traslaci√≥n y escala.

## ‚ú® Caracter√≠sticas

- ‚úÖ Entrenamiento offline de firmas de gestos est√°ticos
- ‚úÖ Invariante a traslaci√≥n y escala (normalizaci√≥n centering + L2)
- ‚úÖ Detecci√≥n online en tiempo real con webcam
- ‚úÖ C√°lculo autom√°tico de umbrales basado en percentiles
- ‚úÖ Exportaci√≥n a JSON para integraci√≥n con backend C#
- ‚úÖ Visualizaci√≥n en tiempo real de similitudes coseno
- ‚úÖ Optimizaci√≥n de firmas con t√©cnicas avanzadas (PCA whitening, amplificaci√≥n)

---

## üì¶ Requisitos

```txt
opencv-python>=4.8.0
mediapipe>=0.10.0
numpy>=1.24.0
```

Python: 3.8 o superior

---

## üöÄ Instalaci√≥n

1) Ubicarse en el proyecto

```bash
cd GESTOS
```

2) Crear entorno virtual (recomendado)

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux/Mac
source .venv/bin/activate
```

3) Instalar dependencias

```bash
pip install -r requirements.txt
```

---

## üìä Ejemplo de JSON Generado

```json
{
  "nombre": "curioso",
  "tipo": "unimanual",
  "dimensiones": 42,
  "firma_promedio": [
    0.0123, -0.0456, 0.0789, ..., -0.0234
  ],
  "sigma": 0.0245,
  "umbral": 0.0588,
  "algoritmo": "POSE_STATIC_FULLHAND_CENTERED_NORMALIZED",
  "estadisticas": {
    "distancia_media": 0.0245,
    "distancia_maxima": 0.0567,
    "distancia_minima": 0.0012,
    "percentil_95": 0.049,
    "norma_promedio_original": 0.89
  },
  "metadata": {
    "frames_estables": 45,
    "frames_totales": 120,
    "fecha_entrenamiento": "2025-12-29T14:32:18.123456",
    "num_landmarks": 21
  }
}
```

---

## üéØ Workflow Recomendado

### Para Entrenamiento Inicial

```bash
# 1. Crear y activar entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Grabar video del gesto (3-5 segundos, mano quieta)
# Usar tel√©fono, webcam o c√°mara - formato: .mov, .mp4, .avi

# 4. Entrenar gesto
python train_gesture.py --video curioso.mov --gesture-name curioso

# 5. Ver el JSON generado
type curioso_firma.json  # Windows
cat curioso_firma.json   # Linux/Mac
```

### Para Validaci√≥n en Webcam

```bash
# 1. Entrenar m√≠nimo 2 gestos (ej: curioso, inteligencia)
python train_gesture.py --video curioso.mov --gesture-name curioso
python train_gesture.py --video inteligencia.mov --gesture-name inteligencia
```

### Para Exportar a C#

```bash
# 1. Entrenar todos los gestos necesarios
for gesto in curioso inteligencia adaptar;
do
    python train_gesture.py --video $gesto.mov --gesture-name $gesto
done

# 2. (Opcional) Optimizar firmas si detecci√≥n es baja
python optimize_signatures.py

# 3. Copiar JSONs a tu proyecto C#
# cp *.json /ruta/proyecto/csharp/gestures/
```

---

## ‚ö° Consejos Pr√°cticos

‚úÖ **HACER**:
- Grabar videos en ambiente bien iluminado
- Mantener la mano **completamente visible** en el frame
- Usar fondo simple (evita sombras complicadas)
- Hacer el gesto de forma **clara y decidida**
- Dejar la mano quieta al final del gesto (estado estable)

‚ùå **EVITAR**:
- Cambios r√°pidos de iluminaci√≥n durante la grabaci√≥n
- Mano parcialmente fuera del frame
- Gestos muy peque√±os o movimientos micro
- Movimientos innecesarios despu√©s del gesto
- Videos menores a 2 segundos

---

## üêõ Debug y Logging

### Ver informaci√≥n de entrenamiento

```bash
python train_gesture.py --video curioso.mov --gesture-name curioso
# Mostrar√°:
# - N√∫mero de frames estables
# - Distancia media, m√≠n, m√°x
# - Percentil 95
# - Umbral calculado
```

### Verificar JSON manualmente

```bash
python -c "import json; data=json.load(open('curioso_firma.json')); print(f\"Umbral: {data['umbral']}, Sigma: {data['sigma']}, Frames: {data['metadata']['frames_estables']}\")"
```

---

## üîÑ Flujo de Trabajo

```
Video del gesto ‚Üí train_gesture.py
        ‚Üì
Extracci√≥n de keypoints (21 landmarks √ó 2 coords = 42D)
        ‚Üì
Normalizaci√≥n: centrado + divisi√≥n por norma L2
        ‚Üì
C√°lculo de firma: promedio de poses normalizadas
        ‚Üì
C√°lculo de umbral: percentil 95 + 20% margen
        ‚Üì
üìÅ Salida: <gesto>_firma.json
        
        ‚Üì (Fase Offline)
        
        ‚Üì (Fase Online)
        
Webcam ‚Üí detect_gesture.py
        ‚Üì
Extracci√≥n keypoints en tiempo real
        ‚Üì
Buffer circular de N frames
        ‚Üì
Similitud coseno: cos(P_d, F_d,i)
        ‚Üì
Comparar con umbral ‚Üí DETECTADO/NO DETECTADO
        ‚Üì
Panel visual con resultados
```

---

## üìö Comandos Detallados

### Script: `train_gesture.py` (Entrenamiento de Firma)

Entrena una posici√≥n/gesto est√°tico y genera su firma normalizada.

**Uso b√°sico:**

```bash
python train_gesture.py --video <archivo.mov> --gesture-name <nombre>
```

**Ejemplos:**

```bash
# Entrenamiento simple (pose est√°tica)
python train_gesture.py --video curioso.mov --gesture-name curioso

# Reducir requisito de estabilidad (m√°s tolerante)
python train_gesture.py --video curioso.mov --gesture-name curioso --stability-threshold 0.05 --min-frames 3

# Modo sin GUI (servidor)
python train_gesture.py --video inteligencia.mov --gesture-name inteligencia --headless

# Aumentar tolerancia de detecci√≥n MediaPipe
python train_gesture.py --video inteligencia.mov --gesture-name inteligencia --min-detection 0.3
```

**Par√°metros principales:**

| Par√°metro | Descripci√≥n | Default | Rango |
|-----------|-------------|---------|-------|
| `--video, -v` | Ruta del video (requerido) | - | - |
| `--gesture-name, -g` | Nombre del gesto (requerido) | - | - |
| `--stability-threshold` | Cambio m√°ximo permitido entre frames | 0.03 | 0.01 - 0.1 |
| `--min-frames` | Frames estables m√≠nimos | 5 | 3 - 30 |
| `--min-detection` | Confianza m√≠nima MediaPipe | 0.5 | 0.1 - 0.9 |
| `--min-tracking` | Confianza tracking MediaPipe | 0.5 | 0.1 - 0.9 |
| `--headless` | Sin ventana visual | False | Flag |

**Salida del entrenamiento:**

- `<gesto>_firma.json` - Metadatos y firma normalizada (42 dimensiones)

**Ejemplo de JSON generado:**

```json
{
  "nombre": "curioso",
  "tipo": "unimanual",
  "dimensiones": 42,
  "firma_promedio": [...],
  "sigma": 0.0245,
  "umbral": 0.0588,
  "algoritmo": "POSE_STATIC_FULLHAND_CENTERED_NORMALIZED",
  "estadisticas": {
    "distancia_media": 0.0245,
    "distancia_maxima": 0.0567,
    "distancia_minima": 0.0012,
    "percentil_95": 0.049,
    "norma_promedio_original": 0.89
  },
  "metadata": {
    "frames_estables": 45,
    "frames_totales": 120,
    "fecha_entrenamiento": "2025-12-29T...",
    "num_landmarks": 21
  }
}
```

---

### Script: `optimize_signatures.py` (Optimizaci√≥n de Firmas)

Optimiza m√∫ltiples firmas para mejorar discriminaci√≥n entre gestos.

**Requisitos previos:**

Edita las rutas en el script:

```python
INPUT_DIR = r"C:\ruta\donde\estan\los\*.json"
OUTPUT_DIR = r"C:\ruta\salida\gestures_optimized"
```

**T√©cnicas de optimizaci√≥n:**

- **PCA Whitening**: Decorrelaciona y normaliza varianza
- **Feature Scaling**: Amplifica caracter√≠sticas discriminativas
- **Amplification Factor**: Aumenta diferencias respecto al centroide
- **Threshold Adjustment**: Recalcula umbrales √≥ptimos

**Ejecuci√≥n:**

```bash
python optimize_signatures.py
```

Genera JSON optimizados en `OUTPUT_DIR`.

---

---

## üß© Integraci√≥n con Backend C#

### Flujo de Deployement

1. **Entrenamiento** (Fase Offline)
   ```bash
   python train_gesture.py --video curioso.mov --gesture-name curioso
   ```
   Genera: `a_firma.json`

2. **Copiado a C#**
   - Copia `<gesto>_firma.json` a tu proyecto MVC
   - Mapea los campos JSON a tu modelo C#

3. **Uso en Backend**
   - Lee `firma_promedio` (vector de 42 dimensiones normalizado)
   - Lee `umbral` para decisi√≥n binaria
   - Lee `sigma` para estad√≠sticas/logging
   - Aplica la MISMA normalizaci√≥n al procesar keypoints en runtime

### Campos JSON Clave para C#

```json
{
  "nombre": "curioso",                    // ID del gesto
  "tipo": "unimanual",                    // Solo mano derecha
  "dimensiones": 42,                      // 21 landmarks √ó 2 coords
  "firma_promedio": [...],                // Vector de firma (array de 42 floats)
  "sigma": 0.0245,                        // Variabilidad entrenada
  "umbral": 0.0588,                       // Umbral de detecci√≥n
  "algoritmo": "POSE_STATIC_FULLHAND_CENTERED_NORMALIZED"
}
```

### Pseudoc√≥digo C# para Detecci√≥n

```csharp
// En el cliente (cada frame)
var pose = ExtractHandKeypoints(landmarks);  // 42D
var normalized = NormalizePose(pose);        // Centrado + L2

// En el servidor (buffer de N frames)
var bufferAvg = Buffer.Average();            // P_d = promedio buffer
var similarity = CosineSimilarity(bufferAvg, firma.SignatureVector);

if (similarity >= firma.Threshold)
{
    DetectedGesture = firma.Name;
}
```

### Normalizaci√≥n CR√çTICA

La normalizaci√≥n debe ser **id√©ntica** en Python (entrenamiento) y C# (producci√≥n):

```
1. Centrado:    pose_centered = pose - mean(pose)
2. Normalizar:  pose_norm = pose_centered / norm(pose_centered)
```

Este paso es obligatorio para que el gesto se reconozca correctamente.

---

## üìÅ Estructura de Archivos

```
GESTOS/
‚îú‚îÄ‚îÄ .venv/                          # Entorno virtual
‚îú‚îÄ‚îÄ README.md                        # Este archivo
‚îú‚îÄ‚îÄ requirements.txt                 # Dependencias
‚îú‚îÄ‚îÄ train_gesture.py                 # Entrenamiento de gestos
‚îú‚îÄ‚îÄ detect_gesture.py                # Detecci√≥n online
‚îú‚îÄ‚îÄ optimize_signatures.py           # Optimizaci√≥n de firmas
‚îÇ
‚îú‚îÄ‚îÄ curioso_firma.json               # Firma entrenada (ejemplo)
‚îú‚îÄ‚îÄ inteligencia_firma.json          # Otra firma entrenada (ejemplo)
‚îÇ
‚îú‚îÄ‚îÄ videos_gestos/                   # Carpeta donde debes poner los videos de los gestos
‚îÇ   
‚îÇ
‚îî‚îÄ‚îÄ gestures_optimized/              # Firmas optimizadas (salida)
    ‚îú‚îÄ‚îÄ curioso.json
    ‚îî‚îÄ‚îÄ inteligencia.json

```

---

## üîß Soluci√≥n de Problemas

### Problema: "Muy pocos frames estables"

**Causa**: La mano se mueve demasiado o el video es muy corto.

**Soluciones**:
```bash
# Reducir exigencia de estabilidad
python train_gesture.py --video curioso.mov --gesture-name curioso --stability-threshold 0.05

# Reducir frames m√≠nimos
python train_gesture.py --video curioso.mov --gesture-name curioso --min-frames 3

# Aumentar tolerancia MediaPipe
python train_gesture.py --video curioso.mov --gesture-name curioso --min-detection 0.3
```

---

### Problema: Detecci√≥n poco fiable (falsos positivos)

**Causa**: El umbral es demasiado bajo o la firma no es representativa.

**Soluciones**:
- Regrabar con gesto m√°s estable y definido
- Usar `--buffer-size` mayor en `detect_gesture.py` (ej: 15)
- Optimizar firmas con `optimize_signatures.py`

---

## üßÆ Modelo Matem√°tico

### Notaci√≥n

- `f_t ‚àà ‚Ñù‚Å¥¬≤` - Vector de pose (21 landmarks √ó 2 coords)
- `F_d,i ‚àà ‚Ñù‚Å¥¬≤` - Firma del gesto (normalizada)
- `P_d ‚àà ‚Ñù‚Å¥¬≤` - Promedio del buffer temporal
- `œÉ` - Variabilidad (desviaci√≥n est√°ndar de distancias)

### Algoritmo

**1. Normalizaci√≥n (Entrenamiento)**
```
pose_centered = f - mean(f)
pose_norm = pose_centered / ||pose_centered||‚ÇÇ
```

**2. Firma (Entrenamiento)**
```
F_d,i = (1/M) Œ£ pose_norm  (promedio de M poses normalizadas)
```

**3. Umbral (Entrenamiento)**
```
umbral = percentil_95(distancias) √ó 1.2
```

**4. Similitud (Detecci√≥n)**
```
sim = cos(P_d, F_d,i) = (P_d ¬∑ F_d,i) / (||P_d|| ¬∑ ||F_d,i||)
```

**5. Decisi√≥n (Detecci√≥n)**
```
if sim >= umbral:
    GESTO DETECTADO
else:
    NO DETECTADO
```

---

## üèóÔ∏è Arquitectura T√©cnica

### Componentes

1. **MediaPipe Hands** (Input)
   - Extrae 21 landmarks por mano
   - Retorna coordenadas normalizadas (0-1)
   - Ofrece confianza de detecci√≥n y tracking

2. **Normalizaci√≥n** (Preprocessing)
   - Centrado: `pose - mean(pose)`
   - L2 Normalization: `pose / norm(pose)`
   - Invariante a traslaci√≥n y escala

3. **Firma (Signature)** (Modelo)
   - Promedio de poses normalizadas
   - Vector 42-dimensional
   - Representa gesto "can√≥nico"

4. **Umbral (Threshold)**
   - Basado en percentil 95 de distancias
   - M√°s robusto que umbrales fijos
   - Adapta a variabilidad del entrenamiento

5. **Detecci√≥n Online**
   - Buffer circular de N frames
   - Promedio del buffer
   - Similitud coseno vs firma
   - Cooldown anti-rebote

### Archivos Clave

| Archivo | L√≠neas | Funci√≥n |
|---------|--------|---------|
| `train_gesture.py` | 224 | Entrenamiento de firmas |
| `optimize_signatures.py` | 310 | Optimizaci√≥n batch |

---

## üìã Validaci√≥n de Entrada

La siguiente tabla muestra qu√© verifica cada script:

| Validaci√≥n | Train | Detect | Optimize |
|------------|-------|--------|----------|
| Archivo video existe | ‚úÖ | - | - |
| Archivo JSON existe | - | ‚úÖ | ‚úÖ |
| MediaPipe detecta mano | ‚úÖ | ‚úÖ | - |
| Frames estables suficientes | ‚úÖ | - | - |
| Compatibilidad dimensiones | ‚úÖ | ‚úÖ | ‚úÖ |

---

## üîë Par√°metros Cr√≠ticos

### `stability_threshold` (train_gesture.py)
- **Qu√© es**: Cambio m√°ximo entre frames para considerarlo estable
- **Default**: 0.03
- **Aumentar si**: Video es inestable, hay vibraci√≥n peque√±a
- **Reducir si**: Aceptas movimiento leve durante entrenamiento
- **Rango t√≠pico**: 0.01 - 0.1

### `buffer_size` (detect_gesture.py)
- **Qu√© es**: N√∫mero de frames para promediar antes de evaluar
- **Default**: 10
- **Aumentar si**: Detecci√≥n es muy sensible, muchos falsos positivos
- **Reducir si**: Necesitas respuesta r√°pida
- **Rango t√≠pico**: 5 - 20

### `cooldown` (detect_gesture.py)
- **Qu√© es**: Frames a esperar antes de permitir nueva detecci√≥n
- **Default**: 20
- **Aumentar si**: Detecta el mismo gesto m√∫ltiples veces
- **Reducir si**: Necesitas detectar gestos r√°pidamente
- **Rango t√≠pico**: 10 - 40

---

## üéì Limitaciones Conocidas

### Generales

1. **Solo gestos est√°ticos**: No detecta gestos din√°micos (movimiento continuo)
2. **Una mano por frame**: Aunque se puede entrenar bimanual, detect espera una sola
3. **Dependencia de iluminaci√≥n**: Var√≠a significativamente con condiciones de luz
4. **Oclusiones parciales**: Si dedos est√°n ocultos, MediaPipe falla

### Matem√°ticas

1. **Similitud coseno**: No captura diferencias de amplitud (ambas normalizadas)
2. **Percentil fijo**: El umbral es est√°tico (no se adapta en runtime)
3. **Invariancia incompleta**: Centro en eje XY pero no en rotaci√≥n

---
